# Correction Examples for Few-Shot Learning (P1-2)

**Status**: âœ… Completed (2026-02-19)
**Tests**: 21 passing
**Priority**: P1 (High ROI improvement)

## Overview

This feature stores full transaction examples when users correct categories, enabling **few-shot prompting** to improve GPT classification accuracy. When users have corrected similar transactions before, the system shows those examples in the GPT prompt to guide better decisions.

### Key Benefits

- **Improved GPT Accuracy**: Learn from user corrections to classify similar transactions correctly
- **Contextual Learning**: Show relevant examples based on similarity and category
- **Quality Tracking**: Monitor which examples are most helpful via usage metrics
- **User-Specific + Global**: Combine personal preferences with community patterns

---

## Architecture

### Components

```
src/migrations/
â””â”€â”€ 002_correction_examples.sql      # Database schema for correction_examples table

src/lib/agents/tools/utils/
â””â”€â”€ example-retriever.ts              # Retrieval and formatting utilities

src/lib/agents/tools/
â””â”€â”€ update-transaction.ts             # Integrated: saves examples on category correction

src/__tests__/agents/tools/utils/
â””â”€â”€ example-retriever.test.ts         # 21 tests
```

### Database Schema

**Table**: `public.correction_examples`

| Column         | Type      | Description                                      |
| -------------- | --------- | ------------------------------------------------ |
| id             | UUID      | Primary key                                      |
| user_id        | UUID      | User ID (nullable for global examples)           |
| concept        | TEXT      | Transaction concept (normalized lowercase)       |
| amount         | FLOAT     | Transaction amount                               |
| date           | DATE      | Transaction date                                 |
| old_category   | TEXT      | Category before correction (GPT's mistake)       |
| new_category   | TEXT      | Category after correction (correct answer)       |
| merchant       | TEXT      | Extracted merchant name (nullable)               |
| transaction_id | UUID      | Reference to original transaction                |
| confidence     | FLOAT     | Quality score (1.0 = user correction)            |
| times_used     | INT       | Usage tracking (how many times used in prompts)  |
| created_at     | TIMESTAMP | Creation timestamp                               |
| last_used_at   | TIMESTAMP | Last time used in prompt                         |

**Unique Constraint**: `(user_id, concept, old_category, new_category)` - prevent duplicate examples

### Helper Functions (SQL)

1. **`save_correction_example(...)`**
   - Saves a correction example
   - Upserts on conflict (updates if example already exists)

2. **`get_relevant_examples(user_id, category, limit)`**
   - Gets relevant examples for few-shot prompting
   - Priority: user-specific > global (min 3 times_used)
   - Returns: concept, old_category, new_category, merchant, confidence

3. **`increment_example_usage(example_id)`**
   - Increments times_used counter
   - Updates last_used_at timestamp

4. **`get_example_stats(user_id)`**
   - Returns statistics about saved examples
   - Returns: total_examples, examples_by_category, most_corrected, correction_count

---

## How It Works

### 1. Saving Examples (Automatic)

When a user corrects a transaction category via `update-transaction`:

```typescript
// This happens AUTOMATICALLY in update-transaction.ts
// When user changes category: opcional â†’ supervivencia

// Step 1: Learn merchant rule (P1-1)
await learnFromCorrection(supabase, userId, concept, oldCategory, newCategory);

// Step 2: Save full example (P1-2)
await supabase.rpc("save_correction_example", {
  p_user_id: userId,
  p_concept: "mercadona compra semanal",
  p_amount: 45.0,
  p_date: "2026-02-19",
  p_old_category: "opcional",
  p_new_category: "supervivencia",
  p_merchant: "mercadona",
  p_transaction_id: transactionId,
  p_confidence: 1.0, // User explicit correction
});
```

**What gets saved**:
- Full transaction context (concept, amount, date)
- What GPT got wrong (old_category)
- What the correct answer is (new_category)
- Extracted merchant (if available)
- Reference to original transaction

### 2. Retrieving Examples for Few-Shot Prompting

Before asking GPT to classify a transaction, retrieve relevant examples:

```typescript
import { getRelevantExamples, formatExamplesForPrompt } from "@/lib/agents/tools/utils/example-retriever";

// Get examples for a specific category
const examples = await getRelevantExamples(supabase, userId, {
  categoryFilter: "supervivencia",
  limit: 3,
  minConfidence: 0.8,
});

// Format for GPT prompt
const formatted = formatExamplesForPrompt(examples);
// â†’ "AquÃ­ hay transacciones similares que has corregido antes:
//    - 'mercadona compra semanal' â†’ supervivencia (antes: opcional)
//    - 'lidl productos' â†’ supervivencia (antes: opcional)
//    - 'carrefour mensual' â†’ supervivencia (antes: opcional)"
```

### 3. Using Examples in GPT Prompt

Add formatted examples to the GPT system prompt:

```typescript
const systemPrompt = `
You are a financial assistant helping classify transactions.

${formatted}

Based on these examples, classify the following transaction:
Concept: "${newConcept}"
Amount: ${amount}â‚¬
Date: ${date}

Category: ___
`;
```

**GPT sees**:
- Similar transactions the user has corrected before
- What GPT got wrong (old_category)
- What the correct answer is (new_category)
- This guides GPT to make better decisions

### 4. Tracking Usage

After using examples in a prompt, track which ones were helpful:

```typescript
import { trackExampleUsage } from "@/lib/agents/tools/utils/example-retriever";

// After classification
await trackExampleUsage(supabase, [
  "example-uuid-1",
  "example-uuid-2",
  "example-uuid-3",
]);
```

**Why track usage**:
- Identifies most helpful examples (high times_used = useful)
- Prioritizes proven examples over untested ones
- Helps with quality metrics

---

## Integration Status

### âœ… Completed

- [x] Database migration created (`002_correction_examples.sql`)
- [x] Example retrieval utilities implemented
- [x] Integrated into `update-transaction.ts` (saves examples automatically)
- [x] Formatting utilities for GPT prompts
- [x] Usage tracking implemented
- [x] Statistics functions implemented
- [x] 21 unit tests passing

### ðŸ”„ Pending Integration

These utilities are **ready to use** but not yet integrated into the GPT classification flow:

1. **GPT Prompt Enhancement** (Next Step)
   - Modify `function-caller.ts` or GPT prompts to include examples
   - Call `getRelevantExamples()` before classification
   - Add `formatExamplesForPrompt()` output to system prompt
   - Track usage with `trackExampleUsage()` after classification

2. **Similarity-Based Retrieval** (Optional Enhancement)
   - Use `getSimilarExamples()` instead of category filter
   - Shows examples with similar concepts (keyword matching)
   - More contextually relevant than category-only

---

## Usage Examples

### Example 1: Get Examples for a Category

```typescript
const examples = await getRelevantExamples(supabase, userId, {
  categoryFilter: "supervivencia",
  limit: 3,
});

console.log(examples);
// [
//   { concept: "mercadona compra", oldCategory: "opcional", newCategory: "supervivencia", ... },
//   { concept: "lidl productos", oldCategory: "opcional", newCategory: "supervivencia", ... },
//   { concept: "carrefour mensual", oldCategory: "opcional", newCategory: "supervivencia", ... }
// ]
```

### Example 2: Get Similar Examples

```typescript
const similar = await getSimilarExamples(
  supabase,
  userId,
  "Mercadona productos frescos",
  3
);

// Returns examples with "mercadona" or "productos" in concept
```

### Example 3: Format for GPT Prompt

```typescript
const examples = await getRelevantExamples(supabase, userId, {
  categoryFilter: "supervivencia",
  limit: 3,
});

const formatted = formatExamplesForPrompt(examples, "es");

console.log(formatted);
// AquÃ­ hay transacciones similares que has corregido antes:
//   - "mercadona compra semanal" â†’ supervivencia (antes: opcional)
//   - "lidl productos" â†’ supervivencia (antes: opcional)
//   - "carrefour mensual" â†’ supervivencia (antes: opcional)
```

### Example 4: Get Statistics

```typescript
const stats = await getExampleStats(supabase, userId);

console.log(`Total examples: ${stats.totalExamples}`);
console.log(`Most corrected: ${stats.mostCorrected} (${stats.correctionCount} times)`);
console.log(`By category:`, stats.examplesByCategory);
// {
//   totalExamples: 25,
//   mostCorrected: "opcional",
//   correctionCount: 12,
//   examplesByCategory: { supervivencia: 10, opcional: 12, cultura: 3 }
// }
```

---

## Seed Data

The migration includes 10 common correction examples:

**Supermarkets** (opcional â†’ supervivencia):
- Mercadona compra semanal
- Carrefour compra mensual
- Lidl productos

**Streaming** (supervivencia â†’ opcional):
- Netflix suscripciÃ³n
- Spotify premium
- Amazon Prime mensual

**Education** (opcional â†’ cultura):
- Udemy curso programaciÃ³n
- Casa del Libro novela

**Transport** (opcional â†’ supervivencia):
- Uber viaje trabajo
- Renfe billete Madrid

These provide good initial few-shot examples without requiring user training.

---

## How to Apply Migration

### Option 1: Using Supabase Dashboard

1. Go to Supabase Dashboard â†’ SQL Editor
2. Copy contents of `src/migrations/002_correction_examples.sql`
3. Paste and run the SQL script
4. Verify: Check if `correction_examples` table exists in Database > Tables

### Option 2: Using Supabase CLI

```bash
supabase migration new correction_examples
# Copy contents of 002_correction_examples.sql to the new migration file
supabase db push
```

### Option 3: Using psql

```bash
psql -h <supabase-host> -U postgres -d postgres -f src/migrations/002_correction_examples.sql
```

---

## Testing

All utilities have comprehensive test coverage:

```bash
# Run P1-2 tests (21 tests)
npm test -- example-retriever.test.ts

# Test coverage:
# - getRelevantExamples: 6 tests
# - formatExamplesForPrompt: 4 tests
# - getSimilarExamples: 4 tests
# - trackExampleUsage: 4 tests
# - getExampleStats: 4 tests
```

---

## Performance Considerations

### Latency Impact

- **Save example**: ~20-50ms (DB insert/upsert)
- **Retrieve examples**: ~10-30ms (indexed query)
- **Format for prompt**: <1ms (string concatenation)
- **Track usage**: ~5-15ms per example (RPC call)

### Optimization Opportunities

1. **Batch Usage Tracking**: Track all examples in single RPC call (future enhancement)
2. **Caching**: Cache frequently used examples in Redis
3. **Similarity Scoring**: Replace keyword matching with embedding similarity (P2-1)

---

## Metrics & Success Criteria

After deployment, monitor:

- **Example coverage**: % of transactions with relevant examples
- **Usage distribution**: Which examples are used most (high times_used)
- **Quality signal**: Correlation between example usage and classification accuracy
- **Growth rate**: How fast example library is growing

**Expected Impact**:
- 20-30% improvement in GPT classification accuracy
- 50%+ of transactions have relevant examples within 2 weeks
- Most common categories (supervivencia, opcional) have 10+ examples each

---

## Next Steps

### 1. Integrate into GPT Classification Flow

Modify the main agent to use examples:

```typescript
// In function-caller.ts or wherever GPT classification happens

// Before calling GPT
const examples = await getRelevantExamples(supabase, userId, {
  categoryFilter: predictedCategory, // Or leave empty for general examples
  limit: 3,
});

// Add to system prompt
const systemPrompt = basePrompt + "\n\n" + formatExamplesForPrompt(examples);

// Call GPT with enhanced prompt
const response = await openai.chat.completions.create({
  messages: [
    { role: "system", content: systemPrompt },
    { role: "user", content: userMessage },
  ],
});

// Track which examples were used
if (examples.length > 0) {
  await trackExampleUsage(supabase, examples.map(ex => ex.id));
}
```

### 2. A/B Test Impact

- **Control**: GPT without examples
- **Treatment**: GPT with examples
- **Metric**: Category correction rate (lower = better)
- **Hypothesis**: Examples reduce correction rate by 20-30%

---

## Troubleshooting

### Issue: Examples not being saved

**Symptoms**: `update-transaction` succeeds but no examples in DB

**Solutions**:
1. Verify migration was applied (`SELECT * FROM correction_examples LIMIT 1`)
2. Check RLS policies (user must own the example being created)
3. Look for errors in `apiLogger` output (example save is non-blocking)

### Issue: Retrieved examples not relevant

**Symptoms**: `getRelevantExamples()` returns examples but they don't help

**Solutions**:
1. Increase `minConfidence` threshold (default: 0.8)
2. Use `categoryFilter` to narrow down results
3. Try `getSimilarExamples()` instead (keyword-based matching)

### Issue: Low times_used for all examples

**Symptoms**: All examples have times_used = 0

**Solutions**:
1. Ensure `trackExampleUsage()` is being called after using examples
2. Check if GPT prompt integration is complete
3. Verify `increment_example_usage` RPC function exists

---

## Related Files

- **Implementation**: `src/lib/agents/tools/utils/example-retriever.ts`
- **Migration**: `src/migrations/002_correction_examples.sql`
- **Tests**: `src/__tests__/agents/tools/utils/example-retriever.test.ts`
- **Integration**: `src/lib/agents/tools/update-transaction.ts` (line 215+)

---

## Summary

P1-2 implements a **correction examples system** that stores full transaction details when users correct categories, enabling few-shot prompting to improve GPT accuracy. The system is production-ready with 21 passing tests and automatic saving integrated into `update-transaction`. Next step is to integrate example retrieval into the GPT classification flow to start seeing accuracy improvements.
